{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a CNN for Image Classification on your Custom Dataset\n",
    "\n",
    "Before you proceed with this notebook, you need to have a custom dataset to train your model on. You may use one of the methods suggested in [04_collect_data.ipynb](04_collect_data.ipynb) and make sure your custom dataset in under your `./datasets` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision as tv\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchvision.datasets as datasets \n",
    "from torchvision.transforms import v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get cpu, gpu or mps device for training\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create your directory structure for your datasets and models\n",
    "\n",
    "data_dir = pathlib.Path(\"datasets/gallery_dl_dataset\")\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "models_dir = pathlib.Path(\"models\")\n",
    "models_dir.mkdir(exist_ok=True)\n",
    "\n",
    "model_name = \"image_classifier\" #Â change when working with other datasets\n",
    "\n",
    "model_dir = models_dir / model_name\n",
    "model_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data Processing ~ Image Transformations\n",
    "\n",
    "Could you augment your training data by adding more transformations to them?\n",
    "\n",
    "You could randomly change their brightness, contrast, saturation, and hue.\n",
    "\n",
    "You could flip them horizontally or vertically with a 0.5 probability.\n",
    "\n",
    "You could randomly rotate them.\n",
    "\n",
    "Look in [here](https://pytorch.org/vision/stable/transforms.html) and [here](https://pytorch.org/vision/stable/auto_examples/transforms/plot_transforms_illustrations.html#sphx-glr-auto-examples-transforms-plot-transforms-illustrations-py) for references and examples. \n",
    "\n",
    "Do you need to also add the above transformations to your validation set? Or are the existing ones enough? You need to consider what the purpose of each dataset is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 3 # your number of classes\n",
    "\n",
    "train_transform = v2.Compose([\n",
    "        # v2.Resize(size=(64, 64), antialias=True),\n",
    "        v2.RandomResizedCrop(size=(64, 64), antialias=True),\n",
    "        v2.ToImage(),\n",
    "        v2.ToDtype(torch.float32, scale=True), \n",
    "    ])\n",
    "\n",
    "val_transform = v2.Compose([\n",
    "        v2.Resize(size=(64, 64), antialias=True),\n",
    "        v2.CenterCrop(size=(64, 64)),\n",
    "        v2.ToImage(),\n",
    "        v2.ToDtype(torch.float32, scale=True), \n",
    "    ])\n",
    "\n",
    "# create train and validation datasets with seperate transforms\n",
    "train_dataset = datasets.ImageFolder(data_dir, transform=train_transform)\n",
    "val_dataset = datasets.ImageFolder(data_dir, transform=val_transform)\n",
    "test_dataset = datasets.ImageFolder(data_dir, transform=val_transform)\n",
    "\n",
    "print(\"\\n\".join(train_dataset.classes)) # should show the folder names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create our train, validation and test datasets by splitting the full input dataset into three subsets. A 70-20-10 split is quite common.\n",
    "\n",
    "By setting a `random_state`, we are performing the split randomly but in a deterministic way, i.e. we will always get the same random train_test_split as long as we use the same random_state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get length of the full dataset before split, and save it in idx\n",
    "num_train = len(train_dataset)\n",
    "\n",
    "# define the percentage that will be used for validation\n",
    "val_size = 0.2\n",
    "test_size = 0.1  \n",
    "\n",
    "# create an array of idx numbers for each element of the full dataset\n",
    "idx = list(range(num_train))\n",
    "print(num_train, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform train / val split for data points\n",
    "train_indices, val_indices = train_test_split(idx, test_size=val_size, random_state=42)\n",
    "train_indices, test_indices = train_test_split(train_indices, test_size=test_size/(1 - val_size), random_state=42)  \n",
    "\n",
    "# override datasets to only be samples for each split\n",
    "train_dataset = Subset(train_dataset, train_indices)\n",
    "val_dataset = Subset(val_dataset, val_indices)\n",
    "test_dataset = Subset(test_dataset, test_indices)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observing our Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dataset sizes and sample shape\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "\n",
    "img_num = 92 # change this number to view a different sample\n",
    "\n",
    "# Get a sample to check shape\n",
    "sample_img, sample_label = train_dataset[img_num]\n",
    "print(f\"\\nSample image shape: {sample_img.shape}\")\n",
    "print(f\"Sample label: {sample_label}\")\n",
    "print(f\"Classes: {train_dataset.dataset.classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[img_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\".join(train_dataset.dataset.classes)) # join an array into a string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a sample image and its label\n",
    "sample_img, sample_label = train_dataset[img_num]\n",
    "label_name = train_dataset.dataset.classes[sample_label]\n",
    "\n",
    "# Plot it\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.title(f\"Label: {label_name} (index: {10})\")\n",
    "plt.imshow(sample_img.permute(1, 2, 0))  # Convert from (C, H, W) to (H, W, C) for display\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting for multiple images, randomly selected\n",
    "figure = plt.figure(figsize=(12, 10))\n",
    "cols, rows = 5, 5\n",
    "for i in range(1, cols * rows + 1):\n",
    "    # generate a random index\n",
    "    sample_idx = torch.randint(len(train_dataset), size=(1,)).item()\n",
    "    # retrieve the image and the respective label for that index\n",
    "    img, label = train_dataset[sample_idx]\n",
    "    label_name = train_dataset.dataset.classes[label]\n",
    "    \n",
    "    # create the grid of subplots\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(label_name, fontsize=8)\n",
    "    plt.axis(\"off\")\n",
    "    # Convert from (C, H, W) to (H, W, C) for display\n",
    "    plt.imshow(img.permute(1, 2, 0))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 6\n",
    "\n",
    "# create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "for X, y in val_loader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining our Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNetwork, self).__init__()\n",
    "        # Input shape: [batch, 3, 64, ]\n",
    "        # Breaking down the first conv layer: \n",
    "        #   > 1 input channel for grayscale images\n",
    "        #   > 32 different filters to output\n",
    "        #   > 3x3 kernel size\n",
    "        #   > 1 padding\n",
    "        # output shape: [batch, 64, 64, 64]\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        # 2x2 maxpooling, output shape: [batch, 64, 32, 32]\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        # and so on and so forth ...\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(128 * 8 * 8, 256)\n",
    "        self.fc2 = nn.Linear(256, 3) # change the output size to match your number of classes\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1) \n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Layers and their initial weights/bias shapes:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\" - {name} | Shape: {param.shape} | Sample values: {param.data.flatten()[:5]}...\")\n",
    "\n",
    "print()\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer and Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing our Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(epochs): \n",
    "    train_loss = 0.0\n",
    "    \n",
    "    # training loop\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # get data\n",
    "        inputs = data.to(device)\n",
    "        labels = target.to(device)\n",
    "        \n",
    "        # zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass\n",
    "        predictions = model(inputs)\n",
    "        # compute the loss\n",
    "        loss = loss_fn(predictions, labels)\n",
    "        # backpropagate\n",
    "        loss.backward()\n",
    "        # update the parameters, i.e. weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # save statistics to plot later\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    # validation loop\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        for batch_idx, (data, target) in enumerate(val_loader):\n",
    "            # get data\n",
    "            inputs = data.to(device)\n",
    "            labels = target.to(device)\n",
    "            # forward pass, no backpropagation and optimisation\n",
    "            predictions = model(inputs)\n",
    "            # compute the loss\n",
    "            loss = loss_fn(predictions, labels)\n",
    "            # save statistics to plot later\n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    # normalise cumulative losses to dataset size\n",
    "    train_loss = train_loss / len(train_loader)\n",
    "    val_loss = val_loss / len(val_loader)\n",
    "    \n",
    "    # added cumulative losses to lists to plot later\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    print(f'Epoch {epoch + 1}, train loss: {train_loss:.3f}, val loss: {val_loss:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing ~ Evaluating the Performance of our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Train vs validation loss\")\n",
    "plt.plot(train_losses,label=\"train\")\n",
    "plt.plot(val_losses,label=\"val\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"cumulative loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn, device=device):\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    # average loss across batches and accuracy across samples\n",
    "    test_loss = test_loss / num_batches\n",
    "    accuracy = correct / size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*accuracy):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return test_loss, accuracy\n",
    "\n",
    "# Run test on the test loader\n",
    "test_loss, test_acc = test(test_loader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using our Model on an Input Image\n",
    "\n",
    "\n",
    "See [Transforming and Augmenting Images](https://pytorch.org/vision/stable/transforms.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('images/colorful-carpet-sample.png') # try also images/4.png\n",
    "\n",
    "transforms = v2.Compose([  \n",
    "    # v2.Grayscale(num_output_channels=1),\n",
    "    v2.Resize(size=(64,64), antialias=True),\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "])\n",
    "\n",
    "input = transforms(img).unsqueeze(0)  # ADD BATCH DIMENSION [1, 1, 28, 28]\n",
    "input = input.to(device)\n",
    "\n",
    "print(f\"Input shape: {input.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = nn.Softmax(dim=-1)(model(input)).cpu().numpy()\n",
    "print(f\"Our predictions (shape: {predictions.shape})\")\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predicted = np.argmax(predictions[0]) # argmax: the *index* of the highest prediction\n",
    "\n",
    "plt.figure()\n",
    "plt.title(f'Predicted number: {train_dataset.dataset.classes[predicted]}') # use the predicted category in the title\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot our predictions for all classes using a [bar chart](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.bar.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,5))\n",
    "plt.title(\"Predictions\")\n",
    "xs = train_dataset.dataset.classes     # 0 to 9 for Xs, our ys are our predictions\n",
    "plt.bar(xs, predictions[0]) # a bar chart\n",
    "plt.xticks(xs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.jit.save(torch.jit.script(model), model_dir / f\"my_{model_name}_01.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Do:\n",
    "\n",
    "**Task 1:** Create your own dataset with 2, 3, or more classes, based on one of the suggested approaches. It would be effective to have at least 1000 images/class. Create a folder for each one of your classes and save the respective images there. Then move all of the class folders in `./datasets/name_of_custom_dataset`. Make sure you manually clean-up your data before training, to remove any irrelevant or destroyed images.\n",
    "\n",
    "**Task 2:** Run all the cells in this code to train a classifier on your custom dataset.\n",
    "\n",
    "**Task 3:** Add image transformations on the training dataset. Look in [here](https://pytorch.org/vision/stable/transforms.html) and [here](https://pytorch.org/vision/stable/auto_examples/transforms/plot_transforms_illustrations.html#sphx-glr-auto-examples-transforms-plot-transforms-illustrations-py) for references and examples. \n",
    "\n",
    "**Task 4:** Create a new notebook where you call the model that you just saved from this training and test it on some new unseen data.\n",
    "\n",
    "**Bonus Challenges:**\n",
    "\n",
    "**Bonus 1:** Look into the concept of Early Stopping. What is it? Could it be useful for our training? How? Attempt to implement it by adding the following lines of code after the training loop is completed:\n",
    "\n",
    "   `if val_loss < best_loss:`\n",
    "        \n",
    "        `best_loss = val_loss`\n",
    "        \n",
    "        `torch.save(model.state_dict(), 'best_img_classifier.pt')`\n",
    "\n",
    "For this to work, you will have to initialise best_loss with a high value before you enter the training loop.\n",
    "\n",
    "**Bonus 2:** In this example you are building your classifier from scratch, i.e. you decide yourself what the architecture of the network is and you train it from the very beginning. Could you explore a way for training your classifier based on a pre-trained model? There are many available pre-trained models in [the torchvision models library](https://pytorch.org/vision/stable/models.html), like [ResNet](https://arxiv.org/abs/1512.03385) which is trained on [imagenet dataset](https://www.image-net.org/). This approach will require a few changes and additions in your notebook. Attempt it if you are feeling adventurous!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "dmlcp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
