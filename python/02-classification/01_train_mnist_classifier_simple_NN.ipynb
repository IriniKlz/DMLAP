{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a NN from scratch for Image Classification\n",
    "### Working with the MNIST dataset ~ The *Hello World* of Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we are going to get familiar with using [PyTorch](https://pytorch.org), a deep learning library, to train a simple neural network. The network will be trained on the [MNIST dataset](http://yann.lecun.com/exdb/mnist/) which contains small images of handwritten numerical digits. By the end of this training, the model should be able to accurately classify images with numerical digits.\n",
    "\n",
    "Training a network on the MNIST dataset has become the 'hello world' of machine learning. \n",
    "\n",
    "More info on PyTorch and all the steps we go through in this notebook can be found in the [PyTorch Quickstart](https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision as tv\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets \n",
    "from torchvision.transforms import v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get cpu, gpu or mps device for training\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create your directory structure for your datasets and models\n",
    "\n",
    "data_dir = pathlib.Path(\"datasets\")\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "models_dir = pathlib.Path(\"models\")\n",
    "models_dir.mkdir(exist_ok=True)\n",
    "\n",
    "model_name = \"mnist\" # change when working with other datasets\n",
    "\n",
    "mnist_dir = models_dir / model_name\n",
    "mnist_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data Processing ~ Image Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data does not always come in its final processed form that is required for training machine learning algorithms. We use transforms to perform some manipulation of the data and make it suitable for training. \n",
    "\n",
    "Images are typically stored as PIL images or NumPy n-dim arrays with pixel values in the range [0, 255] (integers). Neural networks in PyTorch expect tensors (multi-dimensional arrays) as inputs, with floating-point values, often normalized to [0., 1.] for better training stability and convergence. The transforms we apply below ensure the data is preprocessed into this \"model-ready\" format.\n",
    "\n",
    "See [here](https://pytorch.org/vision/stable/transforms.html#performance-considerations) for more.\n",
    "\n",
    "All TorchVision datasets have two parameters:\n",
    "- *transform* to modify the features as normalized tensors\n",
    "- *target_transform* to modify the labels and turn them into one-hot encoded tensors (not applicable in this case, because our loss function works with integer labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = v2.Compose([\n",
    "    v2.ToImage(),                         # an updated version of the older conversion .ToTensor()\n",
    "    v2.ToDtype(torch.float32, scale=True) # scales the pixel values from [0, 255] to [0.0, 1.0]\n",
    "])\n",
    "\n",
    "train_data = datasets.MNIST(\n",
    "    root=data_dir,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms,\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=data_dir,\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above, sometimes we need to modify the targets (labels) and turn them into one-hot encoded tensors. The implementation of the loss we are using in this notebook (cross-entropy) accepts integer labels, whereas in various cases that same loss accepts one-hot vectors. \n",
    "\n",
    "If we wanted to perform target transformations, this is what we would do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_classes = 10\n",
    "\n",
    "# target_transform = tv.transforms.Lambda(\n",
    "#     lambda y: torch.zeros(num_classes, dtype=torch.float).scatter_(dim=0, index=torch.tensor(y), value=1)\n",
    "# )\n",
    "# x = 3\n",
    "# print(x)\n",
    "# print(target_transform(x)) # one-hot representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observing our Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data)\n",
    "print(\"-----\")\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data[0])    # returns a tuple (image tensor, label)\n",
    "print(\"-----\")\n",
    "print(train_data[0][1]) # label only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.data.shape, train_data.targets.shape)\n",
    "print(\"-----\")\n",
    "print(test_data.data.shape, test_data.targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\".join(train_data.classes)) # join an array into a string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the difference between the original data type and range, and what happens when you 'call' the dataset to extract a batch, as the model will do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Original data type:    {train_data.data.dtype}\")\n",
    "print(f\"range:                 [{train_data.data.min().item()}: {train_data.data.max().item()}]\")\n",
    "print(f\"Transformed data type: {train_data[0][0].dtype}\")\n",
    "print(f\"range:                 [{train_data[0][0].min().item()}: {train_data[0][0].max().item()}]\")\n",
    "print()\n",
    "\n",
    "print(f\"Original label shape:    {train_data.targets.shape} (60k integers)\")\n",
    "print(f\"dtype:                   {train_data.targets.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_num = 7 # change this number to have a glimpse into another item of the trainset\n",
    "torch.set_printoptions(linewidth=150) # add a wide linewidth to prevent wrapping\n",
    "print(f\"Label: {train_data.targets[img_num]}\")\n",
    "print()\n",
    "print(train_data.data[img_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting for one image\n",
    "plt.figure()\n",
    "plt.title(f\"Label: {train_data.targets[img_num]}\")\n",
    "plt.imshow(train_data.data[img_num], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting for multiple images, randomly selected\n",
    "figure = plt.figure(figsize=(10, 8))\n",
    "cols, rows = 5, 5\n",
    "for i in range(1, cols * rows + 1):\n",
    "    # generate a random index between 0 and len(mnist_trainset)-1, inclusive\n",
    "    sample_idx = torch.randint(len(train_data), size=(1,)).item()\n",
    "    # retrieve the image and the respective label for that index\n",
    "    img, label = train_data[sample_idx]\n",
    "    # create the grid of subplots within the bigger plot\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(label)\n",
    "    plt.axis(\"off\")\n",
    "    # squeeze() removes all dimensions with size 1\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloaders\n",
    "\n",
    "The batch size is only limited by GPU/CPU constains. Generally, we tend to start with a power of 2 (eg 32, 64, 128, 256, 512) for optimal use of GPU capacities. As a general principle, larger batches increase the training speed / epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Training Workflow\n",
    "\n",
    "Heavily based on Jérémie Wenger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "- **Defining our NN, our Model**\n",
    "- **Defining our Optimizer and Loss Function** \n",
    "- **Implementing the Training Loop**   \n",
    "- **Testing our Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining our Neural Network\n",
    "\n",
    "Neural networks comprise of layers/modules that perform operations on data. The torch.nn namespace provides all the building blocks you need to build your own neural network. Every module in PyTorch subclasses the nn.Module. A neural network is a module itself that consists of other modules (layers). This nested structure allows for building and managing complex architectures easily.\n",
    "\n",
    "[See here for more](https://docs.pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html)\n",
    "\n",
    "For estimating the input and output dimensions of our data in the NN below, one needs to remember that MNIST contains images of single digits, so 10 classes, from 0 to 9. All images are grayscale (1 colour channel) with dimensions 28 * 28 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "\n",
    "# Define our fully connected NN \n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self): # the constructor\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten() # [1, 28, 28] -> [1, 28*28]\n",
    "        # a sequence of the layers below, where each layer's output is the next layer's input\n",
    "        # output = input @ weights + bias\n",
    "        # the ReLU activation introduces non-linearity, helping the model learn more complex patterns\n",
    "        self.linear_relu_stack = nn.Sequential( \n",
    "            nn.Linear(28*28, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Layers and their initial weights/bias shapes:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\" - {name} | Shape: {param.shape} | Sample values: {param.data.flatten()[:5]}...\")\n",
    "\n",
    "print()\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters())}\")\n",
    "\n",
    "# Breakdown:\n",
    "# Layer 0: 784*128 weights + 128 biases = 100480 + 128 = 100608\n",
    "# Layer 2: 128*64 weights + 64 biases = 8192 + 64 = 8256\n",
    "# Layer 4: 64*10 weights + 10 biases = 640 + 10 = 650\n",
    "# Total: 100608 + 8256 + 650 = 109514"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer and Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **loss** is how we measure how good our performance is. The cross-entropy loss is a measure of how two probability distributions differ. It calculates the 'distance' between our predictions (a probability distribution) and our labels (*also* a probability distribution, with a 1 where the ground truth is, and zero everywhere else).\n",
    "\n",
    "The **optimizer** will take this loss, and change the parameters of the network in order to improve its performance. You can try different [optimizers](https://pytorch.org/docs/stable/optim.html) from the PyTorch API.\n",
    "\n",
    "The torch.optim.SGD below initialises the Stochastic Gradient Descent (SGD), a typical alorithm for training NNs.\n",
    "\n",
    "The learning rate is a hyperparameter that we can adjust. It control the step size for each update of the weights during backpropagation. Generally, a smaller rate leads to more stable convergence but takes more time, while a larger rate can speed things up but risks missing the optimal loss values (underfitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing our Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the training loop\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset) # total number of samples in the dataset to track progress\n",
    "    losses, accs = [], [] # to store loss and accuracy history\n",
    "\n",
    "    model.train() # set the model to training mode\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(dataloader):\n",
    "        \n",
    "        # 0: data & target to specified device\n",
    "        X, y = data.to(device), target.to(device)\n",
    "        \n",
    "        # 1: prediction - getting logits for each class\n",
    "        pred = model(X)\n",
    "\n",
    "        # 2: loss\n",
    "        loss = loss_fn(pred, y)\n",
    "    \n",
    "        # 3: backpropagation - computes gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # 4: update parameters based on computed gradients\n",
    "        optimizer.step()\n",
    "\n",
    "        # 5: 'zero grad' (otherwise the gradients remain there)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Logging & saving history\n",
    "\n",
    "        # save losses\n",
    "        losses.append(loss.item())\n",
    "        # save our accuracy\n",
    "        accs.append((pred.argmax(1) == y).type(torch.float).mean().item())\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            loss, current = loss.item(), (batch_idx + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "    print()\n",
    "    return losses, accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the test loop\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    \n",
    "    losses, accs = [], []\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "    \n",
    "    model.eval() # set the model to test mode\n",
    "\n",
    "    # no gradients since we are not training!\n",
    "    with torch.no_grad():\n",
    "        for (data, target) in dataloader:\n",
    "\n",
    "            # 0: data & target to specified device\n",
    "            X, y = data.to(device), target.to(device)\n",
    "\n",
    "            # 1: prediction - getting logits for each class\n",
    "            pred = model(X)\n",
    "            \n",
    "            # 2: loss and accuracy\n",
    "            loss = loss_fn(pred, y)\n",
    "            t_l = loss.item()\n",
    "            test_loss += t_l\n",
    "\n",
    "            # accumulate our accuracy\n",
    "            a = (pred.argmax(1) == y).type(torch.float)\n",
    "            correct += a.sum().item()\n",
    "\n",
    "            # save loss and acc\n",
    "            losses.append(t_l)\n",
    "            accs.append(a.mean().item())\n",
    "    \n",
    "    # average loss & results\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    \n",
    "    print(\"Test Error:\")\n",
    "    print(f\"Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f}\")\n",
    "    print()\n",
    "    \n",
    "    return losses, accs, correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**And now onto the actual training!**\n",
    "\n",
    "There are two parameters we need to define, the `batch_size` (already defines in an earlier step) and the number of `epochs`.\n",
    "\n",
    "The number of `epochs` defines how many iterations we perform over the dataset over training. The more epochs in training we perform, the longer the training is going to take, but it often (but not always) leads to better performance.\n",
    "\n",
    "The `batch_size` defines how many data samples we process in parallel during training, this helps speed up training if we use a bigger batch size (but is dependent on the size of the memory of our computer). Using a higher batch size generally leads to better results training, as the weights are updated based on the loss of the whole batch, which leads to more stable training than if we were to update the weights after each single example. Training in batches is a form of *regularisation*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "train_losses, train_accs, test_losses, test_accs = [], [], [], []\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\")\n",
    "    print(\"-------------------------------\")\n",
    "    train_l, train_a = train(train_dataloader, model, loss_fn, optimizer) # per batches losses and accuracies\n",
    "    test_l, test_a, _ = test(test_dataloader, model, loss_fn) # per batches losses and accuracies\n",
    "    # save history\n",
    "    train_losses.extend(train_l)\n",
    "    train_accs.extend(train_a)\n",
    "    test_losses.extend(test_l)\n",
    "    test_accs.extend(test_a)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing ~ Evaluating the Performance of our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Train loss\")\n",
    "plt.plot(train_losses,label=\"train\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"cumulative loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = test(test_dataloader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using our Model on an Input Image\n",
    "\n",
    "\n",
    "See [Transforming and Augmenting Images](https://pytorch.org/vision/stable/transforms.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('images/3.png') # try also images/4.png\n",
    "\n",
    "transforms = v2.Compose([  \n",
    "    v2.Grayscale(num_output_channels=1),\n",
    "    v2.Resize(size=(28,28), antialias=True),\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True), # from [0,255] to [0,1]\n",
    "])\n",
    "\n",
    "input = transforms(img)\n",
    "input = input.to(device)\n",
    "\n",
    "print(f\"Input shape: {input.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = nn.Softmax(dim=-1)(model(input)).cpu().numpy()\n",
    "print(f\"Our predictions (shape: {predictions.shape})\")\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# note that predictions is still *batched* (shape: (1,10)), we need to fetch the first array\n",
    "predicted = np.argmax(predictions[0]) # argmax: the *index* of the highest prediction\n",
    "\n",
    "plt.figure()\n",
    "plt.title(f'Predicted number: {train_data.classes[predicted]}') # use the predicted category in the title\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot our predictions for all classes using a [bar chart](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.bar.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,5))\n",
    "plt.title(\"Predictions\")\n",
    "xs = train_data.classes     # 0 to 9 for Xs, our ys are our predictions\n",
    "plt.bar(xs, predictions[0]) # a bar chart\n",
    "plt.xticks(xs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving & Loading Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# save (reload using torch.jit.load)\n",
    "torch.jit.save(torch.jit.script(model), mnist_dir / f\"{model_name}_scripted.pt\")\n",
    "\n",
    "# save (reload using model.load_state_dict, requires the model class!)\n",
    "torch.save(model.state_dict(), mnist_dir / f\"{model_name}.pt\")\n",
    "print(f\"Saved PyTorch Model State to {mnist_dir / model_name}.pt\")\n",
    "\n",
    "# instantiate then load (you need to have defined NeuralNetwork)!\n",
    "model_reloaded = NeuralNetwork().to(device)\n",
    "model_reloaded.load_state_dict(torch.load(mnist_dir / f\"{model_name}.pt\", weights_only=True))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Do:\n",
    "\n",
    "**Task 1:** Run all the cells in this notebook to train a simple NN on the MNIST dataset. While doing that, try to understand what each cell does, even if you do not understand each one of the commands seperately. The important thing is to start comprehending the whole process of the training. Training a NN in PyTorch is a great opportunity to see all the theory of training in practice. Consult [the pytorch documentation page](https://pytorch.org/docs/stable/index.html) for anything you are unsure about. \n",
    "\n",
    "**Task 2:** Add other images of handwritten digits in the data folder and test your model on those within the last sections where you visualise predictions on new input images. You can add images you download from the internet, or you could get more experimental e.g. create handwritten digits on paper and load them here, or create b-w digits in p5/py5 or other environments and test how the model performs on all of these cases. Test the model's limits!\n",
    "\n",
    "**Task 3:** Test this network on the Fashion MNIST dataset. We are currently calling `tv.datasets.MNIST`. You will instead need to call `tv.datasets.FashionMNIST`.\n",
    "\n",
    "**Task 4:** If you feel confident, you may start exploring how to train a NN on your custom dataset. For that you may follow the instructions below. Note, that a fully connected NN like the one we use here, is not ideal for training an image classifier. Next week, we will use CNN which will be much more appropriate for this task. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Notes on Training on a custom dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Provided that you have images in a folder like this:\n",
    "```bash\n",
    "main_directory/\n",
    "...class_a/\n",
    "......image_1.jpg\n",
    "......image_2.jpg\n",
    "...class_b/\n",
    "......image_1.jpg\n",
    "......image_2.jpg\n",
    "```\n",
    "\n",
    "You can then replace the data loading by\n",
    "\n",
    "```python\n",
    "# Model / data parameters\n",
    "num_classes = # your number of classes\n",
    "\n",
    "transforms = transforms.Compose([  \n",
    "    tv.transforms.Grayscale(num_output_channels=1),\n",
    "    tv.transforms.Resize(size=(28,28), antialias=True)\n",
    "])\n",
    "\n",
    "custom_data = tv.datasets.ImageFolder(\n",
    "    data_dir / \"custom_dataset\",\n",
    "    transform=transforms,\n",
    ")\n",
    "\n",
    "print(custom_data)\n",
    "print(\"\\n\".join(custom_data.classes)) # should show the folder names\n",
    "\n",
    "train_data, test_data = torch.utils.data.random_split(custom_data, [.9,.1])\n",
    "print(len(train_data), len(test_data))\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)\n",
    "```\n",
    "\n",
    "See [the documentation](https://pytorch.org/vision/main/generated/torchvision.datasets.ImageFolder.html#torchvision.datasets.ImageFolder).\n",
    "\n",
    "Checking the contents, as well as training and testing your net, should be identical as before."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "dmlap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
