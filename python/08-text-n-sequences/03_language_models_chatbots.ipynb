{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foXvSQKubUBS"
      },
      "source": [
        "# Large Language Models - Chatbots with Gradio\n",
        "\n",
        "Gradio is a web app framework designed to facilitate the development and deployment of ML and DL apps. Have a look at [their website](https://www.gradio.app).\n",
        "\n",
        "The following adapts their [Quickstart Guide](https://www.gradio.app/guides/quickstart).\n",
        "\n",
        "Notebook by [Jérémie C. Wegner](https://jeremiewenger.com/about/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IHmAEQ6YEzgj"
      },
      "outputs": [],
      "source": [
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1AZLCYE8dH8Y"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQjmc5fcclCf"
      },
      "source": [
        "---\n",
        "\n",
        "## 1. Intro\n",
        "\n",
        "### Hello, World\n",
        "\n",
        "Docs:\n",
        "\n",
        "- [Textbox](https://www.gradio.app/docs/textbox)\n",
        "- [Interface](https://www.gradio.app/docs/interface)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TkE2Q8gZboTt"
      },
      "outputs": [],
      "source": [
        "def greet(name):\n",
        "    return f\"Hello {name}!\"\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=greet,\n",
        "    inputs=gr.Textbox( # customize your textbox\n",
        "        lines=2,\n",
        "        placeholder=\"Name here...\"\n",
        "        ),\n",
        "    outputs=\"text\"\n",
        ")\n",
        "\n",
        "demo.launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXsOk7NDc36M"
      },
      "source": [
        "### Multiple Input and Output Components\n",
        "\n",
        "Docs:\n",
        "\n",
        "- [Slider](https://www.gradio.app/docs/slider)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "grvYbxeVc3dK"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "\n",
        "# how about adding a second \"checkbox\" as a third input\n",
        "# to allow the user to tick whether it's rainy or not,\n",
        "# and add text that changes accordingly?\n",
        "def greet(name, is_morning, temperature):\n",
        "    salutation = \"Good morning\" if is_morning else \"Good evening\"\n",
        "    greeting = f\"{salutation} {name}. It is {temperature} degrees today\"\n",
        "    celsius = (temperature - 32) * 5 / 9\n",
        "    return greeting, round(celsius, 2)\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=greet,\n",
        "    inputs=[\n",
        "        \"text\",\n",
        "        \"checkbox\",\n",
        "        gr.Slider(0, 100) # you can add a default 'value=75' to your slider if you want\n",
        "    ],\n",
        "    outputs=[     # to add labels, try this (thx ChatGPT!):\n",
        "        \"text\",   #gr.Textbox(label=\"Greeting\"),  # Custom label for the first output\n",
        "        \"number\"  #gr.Number(label=\"Temperature in Celsius\")  # Custom label for the second output\n",
        "    ]\n",
        ")\n",
        "demo.launch()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCo66WSzdy2y"
      },
      "source": [
        "### An Image Example\n",
        "\n",
        "You are obviously free to do whatever you like with your inputs, and they are not limited to text only! Here is an example where we modify an image.\n",
        "\n",
        "Docs:\n",
        "- [Image](https://www.gradio.app/docs/image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rWBSyWcTd10c"
      },
      "outputs": [],
      "source": [
        "def filter(input_img):\n",
        "    # sepia filter\n",
        "    img_filter = np.array([\n",
        "        [0.393, 0.769, 0.189],\n",
        "        [0.349, 0.686, 0.168],\n",
        "        [0.272, 0.534, 0.131]\n",
        "    ])\n",
        "    img_filter = img_filter.astype(np.float64) # make sure the contents are floats\n",
        "    filter_img = input_img.dot(img_filter.T)\n",
        "    filter_img /= filter_img.max()\n",
        "    return filter_img\n",
        "\n",
        "demo = gr.Interface(filter, gr.Image(), \"image\")\n",
        "\n",
        "demo.launch(show_api=False, debug=True)\n",
        "\n",
        "# There are quite a few matrices that have an interesting effect,\n",
        "# it can be a nice idea to go look for others and modify this app\n",
        "# to allow the user to choose between different filters!\n",
        "# Color Inversion\n",
        "# img_filter = np.array([\n",
        "#     [-1, 0, 0],\n",
        "#     [0, -1, 0],\n",
        "#     [0, 0, -1]\n",
        "# ]) + 1\n",
        "\n",
        "# # Cool Filter\n",
        "# img_filter = np.array([\n",
        "#     [0.9, 0, 0],\n",
        "#     [0, 0.9, 0],\n",
        "#     [0, 0, 1.1]\n",
        "# ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkJEn0NPf4F1"
      },
      "source": [
        "### Using Blocks\n",
        "\n",
        "For more control, `Blocks` are the way to go. Here we can play with flipping various kinds of data left/right or upside down!\n",
        "\n",
        "Docs:\n",
        "- [Blocks](https://www.gradio.app/docs/blocks)\n",
        "- [Markdown](https://www.gradio.app/docs/markdown)\n",
        "- [Tab](https://www.gradio.app/docs/tab)\n",
        "- [Button](https://www.gradio.app/docs/button)\n",
        "- [Accordion](https://www.gradio.app/docs/accordion)\n",
        "- [Audio](https://www.gradio.app/docs/audio)\n",
        "\n",
        "Also [`np.fliplr`](https://numpy.org/doc/stable/reference/generated/numpy.fliplr.html) and [`np.flipud`](https://numpy.org/doc/stable/reference/generated/numpy.flipud.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbqIxuwtf5UD"
      },
      "outputs": [],
      "source": [
        "def flip_text(x):\n",
        "    return x[::-1]\n",
        "\n",
        "def flip_image(x):\n",
        "    return np.fliplr(x)  # try also np.flipud\n",
        "\n",
        "# help from ChatGPT (buggy, but still nice) for this!\n",
        "def reverse_audio(audio_data):\n",
        "    # audio_data is a tuple with (sample_rate, audio_array)\n",
        "    # print(audio_data)\n",
        "    sample_rate, audio_array = audio_data\n",
        "    reversed_audio = audio_array[::-1]  # Reverse the audio data\n",
        "    # Return the reversed audio data along with the sample rate\n",
        "    return (sample_rate, reversed_audio)\n",
        "\n",
        "# note the 'with' syntax, to allow you to populate your blocks\n",
        "with gr.Blocks() as demo:\n",
        "    # use markdown syntax in the app\n",
        "    gr.Markdown(\"# Flip text, image, or audio files using this demo.\")\n",
        "    with gr.Tab(\"Flip Text\"):\n",
        "        text_input = gr.Textbox()\n",
        "        text_output = gr.Textbox()\n",
        "        text_button = gr.Button(\"Flip\")\n",
        "    with gr.Tab(\"Flip Image\"):\n",
        "        with gr.Row():\n",
        "            image_input = gr.Image()\n",
        "            image_output = gr.Image()\n",
        "        image_button = gr.Button(\"Flip\")\n",
        "    with gr.Tab(\"Reverse Audio\"):\n",
        "        with gr.Row():\n",
        "            audio_input = gr.Audio()\n",
        "            audio_output = gr.Audio()\n",
        "        audio_button = gr.Button(\"Reverse\")\n",
        "\n",
        "    with gr.Accordion(\"Open for More!\"):\n",
        "        gr.Markdown(\"Look at me...\")\n",
        "\n",
        "    # now we have three different functions, with three different effects, in each one of our tabs!\n",
        "    text_button.click(flip_text, inputs=text_input, outputs=text_output)\n",
        "    image_button.click(flip_image, inputs=image_input, outputs=image_output)\n",
        "    audio_button.click(reverse_audio, inputs=audio_input, outputs=audio_output)\n",
        "\n",
        "demo.launch(show_api=False, debug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaSQor7Dgn_I"
      },
      "source": [
        "---\n",
        "\n",
        "## 2. Chatbots!\n",
        "\n",
        "Adapated from  the [Chatbot](https://www.gradio.app/guides/quickstart#chatbots) part of the Quickstart, [How to Create a Chatbot with Gradio](https://www.gradio.app/guides/creating-a-chatbot-fast#a-streaming-example-using-openai) and [How to Create a Custom Chatbot with Gradio Blocks](https://www.gradio.app/guides/creating-a-custom-chatbot-with-blocks#adding-markdown-images-audio-or-videos).\n",
        "\n",
        "Gradio apps these days are used for two main purposes:\n",
        "- to show off diffusion models (we are doing this too!);\n",
        "- to build chatbots.\n",
        "\n",
        "The [triple threat](https://en.wiktionary.org/wiki/triple_threat) of Huggingface and its Hub of models/tokenizers/datasets, Gradio apps and [Huggingface Spaces](https://huggingface.co/spaces) (to deploy apps and provide GPUS) had made this open-source corp hugely important in the field, and turbocharged the development of this ecosystem.\n",
        "\n",
        "Let's look at some chatbot examples.\n",
        "\n",
        "#### Check out [Huggingface Spaces](https://huggingface.co/spaces)!\n",
        "\n",
        "That works like GitHub in that you create repository following a certain syntax for your app, and then you can edit the app locally, push it to Spaces and see the updates (even if you don't have a GPU on your machine). And just like on GitHub, you can *fork* projects (copy and import someone else's code into your own account and then modify it to make it your own). Check out the [intro guide](https://huggingface.co/spaces/launch)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_mU5gMtgzMD"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    !pip -q install gradio\n",
        "    !pip -q install transformers\n",
        "\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HvkKNor_hCZg"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWJIXorgl08Z"
      },
      "source": [
        "### Example: a chatbot that responds yes or no\n",
        "\n",
        "This is obviously the simplest possible thing you can do, but this logic of randomness can be combined with branches (`if/else`) to create all sorts of elaborate paths of decision guiding your bot's answers: attempts at chatbots before Deep Learning would use elaborate systems like this one (for the literature lovers, see [this](https://drive.google.com/file/d/1v-q2M8ZlCcoCGKvw0rgpmyBg6bbH4DWF/view?usp=sharing), [that](https://drive.google.com/file/d/12-wIbonK8d8w5UXpFM_-nzMfBoDpq4Zq/view?usp=sharing) and [that](https://drive.google.com/file/d/1G_T2MjCQCuLYIQPpe0GnBOu3PO67deyL/view?usp=sharing) articles, for instance).\n",
        "\n",
        "Docs:\n",
        "- [ChatInterface](https://www.gradio.app/docs/chatinterface)\n",
        "\n",
        "And the [`random.choice`](https://docs.python.org/3/library/random.html#functions-for-sequences) function in Python."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0m69KfWlvDG"
      },
      "outputs": [],
      "source": [
        "def random_response(message, history):\n",
        "    return random.choice([\"Yes\", \"No\"])\n",
        "\n",
        "gr.ChatInterface(random_response).launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WOzUno_mEnq"
      },
      "source": [
        "### Another example using the user’s input and history\n",
        "\n",
        "Here you can see that I use both a modulo logic (a bit boring, randomness might be nicer) to decide between three different kinds of answer. Then, in option 2, I randomly pick one interaction in the history, and use the user input!\n",
        "\n",
        "Reminder: `history` is mentioned [here](https://www.gradio.app/guides/quickstart#chatbots).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JSAucYRumLZ5"
      },
      "outputs": [],
      "source": [
        "def sometimes_agree_sometimes_remembers(message, history):\n",
        "    # print(*history, sep=\"\\n\") # you can have a look at the history object if you want\n",
        "    if len(history) % 3 == 0:\n",
        "        return f\"Yes, I do think that '{message}'\"\n",
        "    elif len(history) % 3 == 1:\n",
        "        # history is an array of arrays, each containing [\"user input\", \"bot response\"]\n",
        "        past_message = random.choice(history)[0] # [0] for user input, [1] for bot response\n",
        "        return f\"Wait, didn't you say earlier: '{past_message}'\"\n",
        "    else:\n",
        "        return \"I don't think so\"\n",
        "\n",
        "gr.ChatInterface(sometimes_agree_sometimes_remembers).launch(debug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laxm3HaAmY_O"
      },
      "source": [
        "### Streaming chatbots\n",
        "\n",
        "Isn't it nice if your bot types live instead of giving you a full answer?\n",
        "\n",
        "For that, and any gradual process of answering, use the [`yield` keyword of Python generators](https://realpython.com/introduction-to-python-generators/).\n",
        "\n",
        "See [this part](https://www.gradio.app/guides/creating-a-chatbot-fast#a-streaming-example-using-openai)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRQinLJgmZtR"
      },
      "outputs": [],
      "source": [
        "def slow_echo(message, history):\n",
        "    for i in range(len(message)):\n",
        "        time.sleep(0.3) # try random.random() * .5 (or another number) for irregular typing speed!\n",
        "        yield f\"You typed: {message[: i+1]}\"\n",
        "\n",
        "gr.ChatInterface(slow_echo).queue().launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZU6FJn1jF4g"
      },
      "source": [
        "---\n",
        "\n",
        "## Experiments\n",
        "\n",
        "- You could try to modify this code to work with the latest Llama models by Meta (you must register on [their site](https://ai.meta.com/llama/), then on Huggingface once you get permission, to be able to download the code). After that (same as with various restricted models/datasets/etc. on the Hub), you would need to log into HF:\n",
        "```python\n",
        "from pathlib import Path\n",
        "from huggingface_hub import notebook_login\n",
        "if not (Path.home()/'.huggingface'/'token').exists():\n",
        "    notebook_login()\n",
        "```\n",
        "- Another example that would allow you to play with the cutting-edge LLMs is the [OpenAI example](https://www.gradio.app/guides/creating-a-chatbot-fast#a-streaming-example-using-openai) in the Gradio tutorial. You would first need to register (with credit card) and get an API key on [their website](https://platform.openai.com/)...\n",
        "\n",
        "- Gradio ships with a [`Flagging`](https://www.gradio.app/guides/key-features#styling) logic, that allows you to harvest data from your users for free! You can also implement [`likes`](https://www.gradio.app/guides/creating-a-custom-chatbot-with-blocks#liking-disliking-chat-messages), that could be interesting!\n",
        "\n",
        "- The current trend these days is to work with multimodality (systems that are able to handle more than one type of data: text and images, for instance, or text and music). See [this last part](https://www.gradio.app/guides/creating-a-custom-chatbot-with-blocks#adding-markdown-images-audio-or-videos) of the Gradio Chatbot tutorial for examples, as well as the two apps they recommend [project-baize/Baize-7B](https://huggingface.co/spaces/project-baize/chat-with-baize) and [MAGAer13/mPLUG-Owl](https://huggingface.co/spaces/MAGAer13/mPLUG-Owl) (and as said you could clone these projects, study the code, and transform them into your own project)!\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
